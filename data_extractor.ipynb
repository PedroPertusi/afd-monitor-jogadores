{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PedroPertusi/afd-monitor-jogadores/blob/main/data_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYbPhiJCwzuF"
   },
   "source": [
    "# Monitor de notícias de jogadores de futebol - Campeonato Brasileiro Série A 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca5206",
   "metadata": {},
   "source": [
    "## Objetivo do Notebook\n",
    "Este notebook tem como objetivo extrair e analisar notícias de jogadores de futebol do Campeonato Brasileiro Série A 2025, coletando dados do site Globo Esporte e organizando-os em um formato estruturado para análise posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978e98e",
   "metadata": {},
   "source": [
    "## Bibliotecas e módulos\n",
    "- **BeautifulSoup**: extração de conteúdo HTML\n",
    "- **requests**: requisições HTTP\n",
    "- **re**: expressões regulares para limpeza de texto\n",
    "- **pandas**: manipulação e análise de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7xUpg2do5UNZ"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmQcCCCPxCLs"
   },
   "source": [
    "Função para obter o HTML da página a ser acessada para extração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4b6_pPB8GWG"
   },
   "outputs": [],
   "source": [
    "def baixar_pagina(url):\n",
    "    \"\"\"\n",
    "    Faz uma requisição HTTP GET para a URL fornecida e retorna o conteúdo HTML da página.\n",
    "\n",
    "    Parâmetros:\n",
    "    url (str): Endereço da página a ser baixada.\n",
    "\n",
    "    Retorna:\n",
    "    str: Conteúdo HTML da página como texto decodificado em UTF-8.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"utf-8\"\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5HpOStQxqWX"
   },
   "source": [
    "Função responsável por obter o link de uma notícia contido em seu respectivo título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsbbriIJ8iDQ"
   },
   "outputs": [],
   "source": [
    "def extrair_links_noticias_post(url):\n",
    "    \"\"\"\n",
    "    Extrai os links de notícias de um post de página HTML.\n",
    "\n",
    "    Parâmetros:\n",
    "    url (str): URL da página a partir da qual serão extraídos os links.\n",
    "\n",
    "    Retorna:\n",
    "    List[str]: Lista de URLs obtidas dos elementos <h2><a> encontrados na página.\n",
    "    \"\"\"\n",
    "    html = baixar_pagina(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    titulos = soup.find_all('h2')\n",
    "    links_noticias = []\n",
    "    for titulo in titulos:\n",
    "        a_tag = titulo.find('a')\n",
    "        if a_tag and a_tag.get('href'):\n",
    "            links_noticias.append(a_tag.get('href'))\n",
    "    return links_noticias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyxRC4WB1nU3"
   },
   "source": [
    "Função para extrair o conteúdo de cada notícia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCr0FKiT-voy"
   },
   "outputs": [],
   "source": [
    "def extrair_conteudo_noticia(url):\n",
    "    \"\"\"\n",
    "    Extrai o conteúdo textual de uma notícia a partir da URL fornecida,\n",
    "    filtrando parágrafos relevantes e descartando intertítulos e listas.\n",
    "\n",
    "    Parâmetros:\n",
    "    url (str): Endereço da página da notícia a ser processada.\n",
    "\n",
    "    Retorna:\n",
    "    List[str]: Lista de strings contendo o texto limpo de cada parágrafo\n",
    "               (<p> com classe 'content-text__container') sem intertítulos\n",
    "               (div com classe 'content-intertitle') nem listas (<ul>).\n",
    "    \"\"\"\n",
    "    html = baixar_pagina(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    ps = soup.find_all('p', class_='content-text__container')\n",
    "\n",
    "    textos = []\n",
    "    for p in ps:\n",
    "        # descarta parágrafos que contenham intertítulo ou lista\n",
    "        if p.find('div', class_='content-intertitle') or p.find('ul'):\n",
    "            continue\n",
    "        # extrai texto limpo (inclui <a>, <strong>, etc)\n",
    "        textos.append(p.get_text(\" \", strip=True))\n",
    "    return textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uNhxhf22gu8"
   },
   "source": [
    "Após a definição das funções necessárias para a extração de dados, podemos aplicá-las para realizar a extração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6QWCmiE2pzJ"
   },
   "source": [
    "O site escolhido para a obtenção de notícias foi o Globo Esporte (https://ge.globo.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3_pbxkpeTAwX"
   },
   "outputs": [],
   "source": [
    "times = [\"atletico-mg\", \"bahia\", \"botafogo\", \"bragantino\", \"ceara\", \"corinthians\", \"cruzeiro\", \"flamengo\", \"fluminense\", \"fortaleza\",\n",
    "         \"gremio\", \"internacional\", \"juventude\", \"mirassol\", \"palmeiras\", \"santos\", \"sao-paulo\", \"sport\", \"vasco\", \"vitoria\"]\n",
    "\n",
    "conteudos_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PDIB1MO77iGA"
   },
   "outputs": [],
   "source": [
    "base_url = \"https://ge.globo.com/futebol/times/\"\n",
    "\n",
    "for t in times:\n",
    "  time_url = base_url + t\n",
    "  noticias = extrair_links_noticias_post(time_url)\n",
    "\n",
    "  conteudos = []\n",
    "  for n in noticias:\n",
    "    conteudos.append(extrair_conteudo_noticia(n))\n",
    "\n",
    "  pattern = re.compile(r'^\\+ O ge')\n",
    "  c = [\" \".join(parts) for parts in conteudos if not pattern.match(\" \".join(parts))]\n",
    "\n",
    "  c = [i for i in c if i not in (\" \", \"\")]\n",
    "\n",
    "  conteudos_times[t] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4oGAv_a1S0_W"
   },
   "outputs": [],
   "source": [
    "records = [\n",
    "    (time, noticia)\n",
    "    for time, noticias in conteudos_times.items()\n",
    "    for noticia in noticias\n",
    "]\n",
    "\n",
    "df_time_noticia = pd.DataFrame(records, columns=['time', 'noticia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKCYacLp4Fet"
   },
   "source": [
    "Para verificarmos se a extração foi feita corretamente, vamos exibir o DataFrame construído com os times e suas respectivas notícias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "HUbdX0FdZ66d",
    "outputId": "8f116860-a202-4595-dc6a-a9941481cbdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>noticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atletico-mg</td>\n",
       "      <td>Atlético-MG e Cienciano entram em campo nesta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atletico-mg</td>\n",
       "      <td>O meia-atacante Bernard foi a grande novidade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atletico-mg</td>\n",
       "      <td>Antes de uma partida internacional, é normal o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atletico-mg</td>\n",
       "      <td>O carimbo de “atleta da base” assombrou Rubens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bahia</td>\n",
       "      <td>O Bahia perdeu de virada, por 2 a 1 com o Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>vitoria</td>\n",
       "      <td>O Vitória sofreu mais um duro golpe na tempora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>vitoria</td>\n",
       "      <td>O Vitória foi eliminado da Copa Sul-Americana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>vitoria</td>\n",
       "      <td>O Vitória alcançou o seu principal objetivo pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>vitoria</td>\n",
       "      <td>Agora você pode acompanhar a cobertura do ge t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>vitoria</td>\n",
       "      <td>O Vitória teve roteiro favorável para passar d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time                                            noticia\n",
       "0   atletico-mg  Atlético-MG e Cienciano entram em campo nesta ...\n",
       "1   atletico-mg  O meia-atacante Bernard foi a grande novidade ...\n",
       "2   atletico-mg  Antes de uma partida internacional, é normal o...\n",
       "3   atletico-mg  O carimbo de “atleta da base” assombrou Rubens...\n",
       "4         bahia  O Bahia perdeu de virada, por 2 a 1 com o Inte...\n",
       "..          ...                                                ...\n",
       "89      vitoria  O Vitória sofreu mais um duro golpe na tempora...\n",
       "90      vitoria  O Vitória foi eliminado da Copa Sul-Americana ...\n",
       "91      vitoria  O Vitória alcançou o seu principal objetivo pa...\n",
       "92      vitoria  Agora você pode acompanhar a cobertura do ge t...\n",
       "93      vitoria  O Vitória teve roteiro favorável para passar d...\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_noticia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd7ctyb84zet"
   },
   "source": [
    "Após a validação do DataFrame, podemos salvar estas informações dentro de um arquivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ALbSIfmmafl8"
   },
   "outputs": [],
   "source": [
    "df_time_noticia.to_csv(\"times_noticias.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2c3eb",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "Neste notebook realizamos a extração de notícias de todos os times da Série A 2025, validamos o DataFrame resultante e salvamos os dados em um arquivo CSV para futuras análises."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
